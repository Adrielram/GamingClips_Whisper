#!/usr/bin/env python3
"""
ğŸ¯ TRANSCRIPTOR ULTRA-MEJORADO
=============================
Implementa mejoras especÃ­ficas para los problemas identificados:
1. Palabras correctas (diccionario personalizado)
2. Tiempos muertos (VAD agresivo) 
3. SincronizaciÃ³n temporal (correcciÃ³n de drift)
"""

import os
import sys
import json
import time
import subprocess
from pathlib import Path

def create_gaming_prompt():
    """Prompt especializado con vocabulario gaming argentino"""
    gaming_terms = [
        # Nombres comunes personalizados
        "Gabriel", "Adriel", "Estani", "wilo", "corcho", "ruben", "erizo", "rafa", "rafael", "mate",
        "SebastiÃ¡n", "Alejandro", "Cristian", "DamiÃ¡n", "Ale", "MorÃ¡n", "Diego", "MatÃ­as",
        # Gaming terms
        "respawn", "clutch", "headshot", "camping", "rushing", "lag", "fps", 
        "streaming", "gameplay", "speedrun", "boss", "level up",
        # Argentino gaming
        "che boludo", "quÃ© crack", "tremendo", "genial", "zarpado", "mortal",
        "dale vamos", "buena esa", "gg wp", "ez game", "down", "autista", "gordo", 
        "boludo", "vieja", "tu vieja", "allÃ¡", "pedilo"
    ]
    return ", ".join(gaming_terms)

def configure_aggressive_vad():
    """VAD mÃ¡s agresivo para capturar mÃ¡s audio"""
    return {
        "threshold": 0.35,           # MÃ¡s sensible (default: 0.5)
        "min_speech_duration_ms": 150,  # Speech mÃ¡s corto
        "min_silence_duration_ms": 400, # Pausas mÃ¡s cortas  
        "speech_pad_ms": 250        # MÃ¡s padding
    }

def apply_spelling_corrections(text):
    """Corrige palabras comunes mal transcritas"""
    corrections = {
        # Nombres comunes
        "abriel": "Gabriel",
        "adriel": "Adriel",
        "abri": "Gabi", 
        "ebastiÃ¡n": "SebastiÃ¡n",
        "sebas": "Sebas",
        "ristian": "Cristian",
        "amiÃ¡n": "DamiÃ¡n",
        "estani": "Estani",
        "wilo": "Wilo",
        "corcho": "Corcho",
        "ruben": "RubÃ©n",
        "erizo": "Erizo",
        "rafa": "Rafa",
        "rafael": "Rafael",
        "mate": "Mate",
        "morÃ¡n": "MorÃ¡n",
        
        # Gaming terms
        "geegee": "GG",
        "clutsh": "clutch",
        "headshoot": "headshot",
        "respÃ³n": "respawn",
        "lagh": "lag",
        
        # Argentino
        "che": "che",
        "boludo": "boludo",
        "crack": "crack",
        "pedilo": "pedilo",
        "allÃ¡": "allÃ¡"
    }
    
    corrected = text
    for wrong, correct in corrections.items():
        # Reemplazar tanto en minÃºsculas como con primera letra mayÃºscula
        corrected = corrected.replace(wrong, correct)
        corrected = corrected.replace(wrong.capitalize(), correct.capitalize())
    
    return corrected

def get_video_duration(video_path):
    """Obtiene duraciÃ³n precisa del video"""
    try:
        cmd = [
            "ffprobe", "-v", "quiet", "-print_format", "json",
            "-show_streams", "-select_streams", "v:0", video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        return float(data['streams'][0]['duration'])
    except Exception as e:
        print(f"âš ï¸ No se pudo obtener duraciÃ³n del video: {e}")
        return None

def apply_temporal_correction(segments, video_duration):
    """Corrige drift temporal acumulativo"""
    if not segments or not video_duration:
        return segments
    
    # Calcular factor de correcciÃ³n
    last_segment_end = segments[-1]['end'] 
    drift_factor = video_duration / last_segment_end
    
    if abs(drift_factor - 1.0) > 0.02:  # Solo corregir si hay drift significativo
        print(f"ğŸ”§ Aplicando correcciÃ³n temporal: factor {drift_factor:.4f}")
        
        corrected_segments = []
        for seg in segments:
            # Aplicar correcciÃ³n progresiva
            progress = seg['start'] / last_segment_end
            correction_factor = 1.0 + (drift_factor - 1.0) * progress
            
            corrected_segments.append({
                'start': seg['start'] * correction_factor,
                'end': seg['end'] * correction_factor,
                'text': seg['text']
            })
        return corrected_segments
    
    return segments

def enhance_audio_preprocessing(video_path):
    """Pre-procesamiento mejorado de audio"""
    temp_audio = video_path.replace('.mp4', '_enhanced.wav')
    
    print("ğŸµ Mejorando calidad de audio...")
    cmd = [
        "ffmpeg", "-y", "-i", video_path,
        "-af", 
        "highpass=f=85,"           # Filtro pasa-altos
        "lowpass=f=8000,"          # Filtro pasa-bajos
        "compand=0.01:1,"          # CompresiÃ³n dinÃ¡mica
        "volume=1.8,"              # AmplificaciÃ³n
        "speechnorm=e=12.5",       # NormalizaciÃ³n de voz
        "-ar", "16000", "-ac", "1", # Sample rate y mono
        temp_audio
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        return temp_audio
    except subprocess.CalledProcessError:
        print("âš ï¸ Error en pre-procesamiento, usando audio original")
        return video_path

def transcribe_with_improvements(video_path, output_path):
    """TranscripciÃ³n con todas las mejoras aplicadas"""
    try:
        from faster_whisper import WhisperModel
    except ImportError:
        print("âŒ Error: faster-whisper no estÃ¡ instalado")
        return False
    
    # 1. Pre-procesamiento de audio
    enhanced_audio = enhance_audio_preprocessing(video_path)
    
    # 2. Obtener duraciÃ³n del video
    video_duration = get_video_duration(video_path)
    
    # 3. Configurar modelo
    print("ğŸ§  Cargando modelo con configuraciÃ³n optimizada...")
    try:
        model = WhisperModel("large-v3", device="cuda", compute_type="float16")
        device_info = "GPU (CUDA)"
    except Exception:
        model = WhisperModel("large-v3", device="cpu", compute_type="int8")  
        device_info = "CPU"
    
    print(f"ğŸ’» Dispositivo: {device_info}")
    
    # 4. TranscripciÃ³n mejorada
    print("ğŸ¤ Transcribiendo con mejoras aplicadas...")
    
    segments, info = model.transcribe(
        enhanced_audio,
        # Mejoras para palabras correctas
        initial_prompt=create_gaming_prompt(),
        condition_on_previous_text=True,
        temperature=0.0,
        
        # Mejoras para tiempos muertos
        vad_filter=True,
        vad_parameters=configure_aggressive_vad(),
        no_speech_threshold=0.4,
        log_prob_threshold=-0.8,
        
        # Mejoras para sincronizaciÃ³n
        word_timestamps=True,
        beam_size=5,
        language="es"
    )
    
    print(f"ğŸ—£ï¸ Idioma: {info.language} (confianza: {info.language_probability:.2f})")
    
    # 5. Procesar segmentos
    processed_segments = []
    for segment in segments:
        # Aplicar correcciones ortogrÃ¡ficas
        corrected_text = apply_spelling_corrections(segment.text.strip())
        
        if corrected_text:  # Solo agregar si hay texto
            processed_segments.append({
                'start': segment.start,
                'end': segment.end,
                'text': corrected_text
            })
    
    # 6. CorrecciÃ³n temporal
    if video_duration:
        processed_segments = apply_temporal_correction(processed_segments, video_duration)
    
    # 7. Agrupar por palabras inteligentemente
    final_segments = group_segments_intelligently(processed_segments)
    
    # 8. Guardar resultado
    save_srt_improved(final_segments, output_path)
    
    # Limpiar archivo temporal
    if enhanced_audio != video_path and os.path.exists(enhanced_audio):
        os.remove(enhanced_audio)
    
    return True

def group_segments_intelligently(segments):
    """Agrupa segmentos de manera inteligente para mejor lectura"""
    if not segments:
        return segments
    
    grouped = []
    current_group = []
    current_start = None
    
    for seg in segments:
        words = seg['text'].split()
        
        # Inicializar grupo
        if not current_group:
            current_start = seg['start']
            current_group = words
            continue
        
        # Criterios para nueva lÃ­nea
        duration = seg['end'] - current_start
        should_break = (
            len(current_group) + len(words) > 7 or  # MÃ¡ximo 7 palabras
            duration > 3.0 or                       # MÃ¡ximo 3 segundos
            seg['text'].strip().endswith(('.', '!', '?', ':'))  # PuntuaciÃ³n final
        )
        
        if should_break:
            # Guardar grupo actual
            if current_group:
                grouped.append({
                    'start': current_start,
                    'end': segments[len(grouped)]['end'] if len(grouped) < len(segments) else seg['start'],
                    'text': ' '.join(current_group)
                })
            # Iniciar nuevo grupo
            current_start = seg['start']
            current_group = words
        else:
            # Continuar agrupando
            current_group.extend(words)
    
    # Agregar Ãºltimo grupo
    if current_group:
        grouped.append({
            'start': current_start,
            'end': segments[-1]['end'],
            'text': ' '.join(current_group)
        })
    
    return grouped

def save_srt_improved(segments, output_path):
    """Guarda SRT con formato mejorado"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(segments, 1):
            start_time = format_time_srt(seg['start'])
            end_time = format_time_srt(seg['end'])
            
            f.write(f"{i}\n")
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{seg['text']}\n\n")

def format_time_srt(seconds):
    """Convierte segundos a formato SRT (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def main():
    if len(sys.argv) != 2:
        print("âŒ Uso: python transcribe_mejorado.py <video_file>")
        return
    
    video_path = sys.argv[1]
    
    if not os.path.exists(video_path):
        print(f"âŒ Error: No se encontrÃ³ el archivo {video_path}")
        return
    
    # Generar nombre de salida
    base_path = Path(video_path)
    output_path = base_path.with_suffix('.srt')
    
    print("ğŸ¯ TRANSCRIPCIÃ“N ULTRA-MEJORADA")
    print("=" * 50)
    print(f"ğŸ“¹ Video: {Path(video_path).name}")
    print(f"ğŸ“ Salida: {output_path.name}")
    print()
    print("ğŸš€ Mejoras aplicadas:")
    print("    âœ… Diccionario gaming argentino")
    print("    âœ… VAD agresivo para tiempos muertos")
    print("    âœ… CorrecciÃ³n temporal automÃ¡tica")
    print("    âœ… CorrecciÃ³n ortogrÃ¡fica")
    print("    âœ… Pre-procesamiento de audio")
    print()
    
    start_time = time.time()
    
    if transcribe_with_improvements(video_path, output_path):
        elapsed = time.time() - start_time
        print(f"\nâœ… Â¡TRANSCRIPCIÃ“N MEJORADA COMPLETADA!")
        print(f"â±ï¸ Tiempo: {elapsed:.1f}s")
        print(f"ğŸ“ Archivo: {output_path}")
        print()
        print("ğŸ¯ Mejoras implementadas:")
        print("    ğŸ“ Palabras mÃ¡s precisas")
        print("    ğŸ”Š Mejor detecciÃ³n en ruidos")
        print("    â±ï¸ SincronizaciÃ³n corregida")
    else:
        print("\nâŒ Error en la transcripciÃ³n mejorada")

if __name__ == "__main__":
    main()