#!/usr/bin/env python3
"""
üîß HERRAMIENTA DE AN√ÅLISIS DE TRANSCRIPCI√ìN
==========================================
Analiza la calidad de transcripciones y detecta problemas espec√≠ficos.
"""

import os
import sys
import re
from pathlib import Path
from collections import defaultdict

def analyze_transcription_quality(srt_path):
    """Analiza calidad de un archivo SRT"""
    
    if not os.path.exists(srt_path):
        print(f"‚ùå No se encontr√≥ el archivo: {srt_path}")
        return
    
    print("üîç AN√ÅLISIS DE CALIDAD DE TRANSCRIPCI√ìN")
    print("=" * 50)
    print(f"üìù Archivo: {Path(srt_path).name}")
    print()
    
    # Leer archivo SRT
    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Analizar estructura
    analyze_srt_structure(content)
    
    # Analizar problemas de palabras
    analyze_word_problems(content)
    
    # Analizar tiempos muertos
    analyze_timing_gaps(content)
    
    # Analizar sincronizaci√≥n
    analyze_synchronization_issues(content)

def analyze_srt_structure(content):
    """Analiza estructura b√°sica del SRT"""
    lines = content.strip().split('\n\n')
    subtitles = []
    
    for block in lines:
        block_lines = block.strip().split('\n')
        if len(block_lines) >= 3:
            try:
                # Parsear timestamp
                time_line = block_lines[1]
                start_time, end_time = time_line.split(' --> ')
                text = ' '.join(block_lines[2:])
                
                start_seconds = time_to_seconds(start_time)
                end_seconds = time_to_seconds(end_time)
                
                subtitles.append({
                    'start': start_seconds,
                    'end': end_seconds,
                    'duration': end_seconds - start_seconds,
                    'text': text,
                    'word_count': len(text.split())
                })
            except:
                continue
    
    if not subtitles:
        print("‚ùå No se pudieron parsear los subt√≠tulos")
        return
    
    # Estad√≠sticas generales
    total_subtitles = len(subtitles)
    total_duration = subtitles[-1]['end'] - subtitles[0]['start']
    avg_duration = sum(s['duration'] for s in subtitles) / total_subtitles
    avg_words = sum(s['word_count'] for s in subtitles) / total_subtitles
    
    print("üìä ESTRUCTURA GENERAL:")
    print(f"    üìù Total de subt√≠tulos: {total_subtitles}")
    print(f"    ‚è±Ô∏è Duraci√≥n total: {total_duration:.1f}s")
    print(f"    üìè Duraci√≥n promedio: {avg_duration:.1f}s")
    print(f"    üìñ Palabras promedio: {avg_words:.1f}")
    print()
    
    # Detectar problemas de estructura
    problems = []
    
    # Subt√≠tulos muy largos
    long_subs = [s for s in subtitles if s['duration'] > 4.0]
    if long_subs:
        problems.append(f"‚ö†Ô∏è {len(long_subs)} subt√≠tulos muy largos (>4s)")
    
    # Subt√≠tulos muy cortos
    short_subs = [s for s in subtitles if s['duration'] < 0.5]
    if short_subs:
        problems.append(f"‚ö†Ô∏è {len(short_subs)} subt√≠tulos muy cortos (<0.5s)")
    
    # Muchas palabras por l√≠nea
    dense_subs = [s for s in subtitles if s['word_count'] > 8]
    if dense_subs:
        problems.append(f"‚ö†Ô∏è {len(dense_subs)} subt√≠tulos con muchas palabras (>8)")
    
    if problems:
        print("üö® PROBLEMAS DETECTADOS:")
        for problem in problems:
            print(f"    {problem}")
        print()
    else:
        print("‚úÖ Estructura correcta")
        print()

def analyze_word_problems(content):
    """Analiza problemas de reconocimiento de palabras"""
    print("üî§ AN√ÅLISIS DE PALABRAS:")
    
    # Palabras sospechosas (posibles errores de transcripci√≥n)
    suspicious_patterns = [
        r'\babriel\b',      # Gabriel mal transcrito
        r'\bebasti√°n\b',    # Sebasti√°n mal transcrito
        r'\bristian\b',     # Cristian mal transcrito
        r'\bami√°n\b',       # Dami√°n mal transcrito
        r'\b\w{1,2}\b',     # Palabras muy cortas (posibles errores)
        r'[a-z]{10,}',      # Palabras muy largas sin espacios
        r'\b[BCDFGHJKLMNPQRSTVWXYZ]{3,}\b',  # Consonantes seguidas
    ]
    
    issues_found = []
    
    for pattern in suspicious_patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            issues_found.extend(matches)
    
    # Contar palabras extra√±as
    all_words = re.findall(r'\b\w+\b', content.lower())
    word_freq = defaultdict(int)
    for word in all_words:
        word_freq[word] += 1
    
    # Palabras que aparecen solo una vez (posibles errores)
    rare_words = [word for word, freq in word_freq.items() if freq == 1 and len(word) > 3]
    
    if issues_found or rare_words:
        print(f"    ‚ö†Ô∏è {len(set(issues_found))} palabras sospechosas encontradas")
        if issues_found:
            print(f"       Ejemplos: {', '.join(set(issues_found)[:5])}")
        
        if rare_words and len(rare_words) > 10:
            print(f"    üìù {len(rare_words)} palabras √∫nicas (posibles errores)")
            print(f"       Ejemplos: {', '.join(rare_words[:5])}")
    else:
        print("    ‚úÖ No se detectaron problemas obvios de palabras")
    
    print()

def analyze_timing_gaps(content):
    """Analiza tiempos muertos y huecos en la transcripci√≥n"""
    print("üîá AN√ÅLISIS DE TIEMPOS MUERTOS:")
    
    # Parsear timestamps
    time_pattern = r'(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})'
    timestamps = re.findall(time_pattern, content)
    
    if len(timestamps) < 2:
        print("    ‚ùå No hay suficientes timestamps para analizar")
        return
    
    gaps = []
    previous_end = None
    
    for start_str, end_str in timestamps:
        start_time = time_to_seconds(start_str)
        end_time = time_to_seconds(end_str)
        
        if previous_end is not None:
            gap = start_time - previous_end
            if gap > 2.0:  # Gap mayor a 2 segundos
                gaps.append(gap)
        
        previous_end = end_time
    
    if gaps:
        avg_gap = sum(gaps) / len(gaps)
        max_gap = max(gaps)
        print(f"    ‚ö†Ô∏è {len(gaps)} huecos largos detectados (>2s)")
        print(f"    üìä Hueco promedio: {avg_gap:.1f}s")
        print(f"    üìä Hueco m√°ximo: {max_gap:.1f}s")
        
        if len(gaps) > len(timestamps) * 0.2:
            print("    üö® Muchos tiempos muertos - configurar VAD m√°s agresivo")
    else:
        print("    ‚úÖ No hay tiempos muertos significativos")
    
    print()

def analyze_synchronization_issues(content):
    """Analiza problemas de sincronizaci√≥n temporal"""
    print("‚è±Ô∏è AN√ÅLISIS DE SINCRONIZACI√ìN:")
    
    # Parsear timestamps
    time_pattern = r'(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})'
    timestamps = re.findall(time_pattern, content)
    
    if len(timestamps) < 10:
        print("    ‚ùå No hay suficientes timestamps para an√°lisis de drift")
        return
    
    # Calcular velocidad de subt√≠tulos a lo largo del tiempo
    velocities = []
    window_size = 5
    
    for i in range(len(timestamps) - window_size):
        window_start = time_to_seconds(timestamps[i][0])
        window_end = time_to_seconds(timestamps[i + window_size][1])
        window_duration = window_end - window_start
        
        velocities.append(window_duration / window_size)
    
    if len(velocities) > 2:
        # Detectar aceleraci√≥n/desaceleraci√≥n
        start_velocity = sum(velocities[:3]) / 3
        end_velocity = sum(velocities[-3:]) / 3
        
        velocity_change = (end_velocity - start_velocity) / start_velocity
        
        if abs(velocity_change) > 0.05:  # Cambio mayor al 5%
            direction = "aceleraci√≥n" if velocity_change > 0 else "desaceleraci√≥n"
            print(f"    ‚ö†Ô∏è Drift detectado: {direction} del {abs(velocity_change)*100:.1f}%")
            print("    üîß Recomendaci√≥n: aplicar correcci√≥n temporal")
        else:
            print("    ‚úÖ Sincronizaci√≥n estable")
    
    # Analizar duraci√≥n de subt√≠tulos al final vs inicio
    first_quarter = timestamps[:len(timestamps)//4]
    last_quarter = timestamps[-len(timestamps)//4:]
    
    avg_duration_start = sum(time_to_seconds(end) - time_to_seconds(start) 
                           for start, end in first_quarter) / len(first_quarter)
    avg_duration_end = sum(time_to_seconds(end) - time_to_seconds(start) 
                         for start, end in last_quarter) / len(last_quarter)
    
    duration_change = (avg_duration_end - avg_duration_start) / avg_duration_start
    
    if abs(duration_change) > 0.1:  # Cambio mayor al 10%
        trend = "m√°s largos" if duration_change > 0 else "m√°s cortos"
        print(f"    üìä Subt√≠tulos al final son {abs(duration_change)*100:.1f}% {trend}")
    
    print()

def time_to_seconds(time_str):
    """Convierte timestamp SRT a segundos"""
    # Formato: HH:MM:SS,mmm
    time_str = time_str.replace(',', '.')
    parts = time_str.split(':')
    hours = int(parts[0])
    minutes = int(parts[1])
    seconds = float(parts[2])
    return hours * 3600 + minutes * 60 + seconds

def main():
    if len(sys.argv) != 2:
        print("‚ùå Uso: python analizar_transcripcion.py archivo.srt")
        return
    
    srt_path = sys.argv[1]
    analyze_transcription_quality(srt_path)
    
    print("üí° RECOMENDACIONES:")
    print("    ‚Ä¢ Para palabras incorrectas: usar transcribe_mejorado.py")
    print("    ‚Ä¢ Para tiempos muertos: ajustar VAD m√°s agresivo")
    print("    ‚Ä¢ Para sincronizaci√≥n: aplicar correcci√≥n temporal")
    print()

if __name__ == "__main__":
    main()